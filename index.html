<!DOCTYPE html>
<html lang="en">

<!-- 
The design of this website is based on https://xingxuanli.github.io/ and https://isakzhang.github.io/.
PLS ask for permission & add a link to these websites before you directly copy and apply to yours.
-->

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title> Lidong Bing's Homepage </title>
  <meta name="keywords" content="Lidong Bing, 邴立东, Alibaba DAMO, Language Technology Lab, NLP, Large Language Models">
  <meta name="robots" content="index,follow">
  <link rel="stylesheet" href="./style.css">
  <link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134238626-1"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134238626-1');
  </script>

</head>

<body>
  <div class="container content"> 
  <main>
  <div class="home">

  <div class="mini-intro">
  <img class="avatar" src="img/bing_australia.jpg" alt="LidongBing-photo">

  <h2 id="l.bing">Lidong Bing <span style="font-family:STFangsong">(邴立东)</span></h2>
  Director
  <br>Language Technology Lab 
	  [<a href="https://github.com/DAMO-NLP-SG">GitHub</a>, 
	  <a href="https://huggingface.co/DAMO-NLP-SG">HuggingFace</a>, 
	  <a href="https://www.zhihu.com/people/nlp-13-83">Zhihu</a>, 
	  <a href="https://weibo.com/u/7893523378">Weibo</a>]
  <br>DAMO Academy, Alibaba Group
  <br>Office: Xixi Campus B, Hangzhou, China <code class="language-plaintext highlighter-rouge">AND</code> 51 Bras Basah Rd, Singapore 
  <br>Contact: <code class="language-plaintext highlighter-rouge">l.bing [at] alibaba-inc.com AND binglidong [at] gmail.com</code>
<br>
<br>
<p> 
<font color="#FF4500"> 
<b>JOB OPENINGS NOW!!</b> (<i>Updated in Oct. 2023</i>): <br/> (1) Full-time positions for both 
	<i>fresh graduates</i> (<a href="https://talent-holding.alibaba.com/campus/position-detail?bgCode=YKCNU1&lang=zh&positionId=2020697" target="_blank">NLP</a>, 
	<a href="https://talent-holding.alibaba.com/campus/position-detail?bgCode=YKCNU1&lang=zh&positionId=2024103" target="_blank">multimodality</a>) and 
	<i>experienced candidates</i> (<a href="https://talent-holding.alibaba.com/off-campus/position-detail?lang=zh&positionId=1033435&track_id=SSP1697883314282SyjhtFsJyZ4317" target="_blank">NLP</a>, 
	<a href="https://talent-holding.alibaba.com/off-campus/position-detail?lang=zh&positionId=1032935&track_id=SSP1697883314282jteAyZHEFd7386" target="_blank">multimodality</a>). <br/>
	(2) For intern positions, send your CV to the above email addresses. <br/>
	(3) Base locations: China (Beijing, Hangzhou), Singapore.
</font>
</p>
  <div id="menu">
    <div>
      <a href="#Biography">Bio</a>
    </div>
    <div>
      <a href="#News">News</a>
    </div>
    <div>
      <a href="#Publications">Publication</a>
    </div>
    <div>
      <a href="#Talks">Talk</a>
    </div>
    <div>
      <a href="#Professional_Activities">Service</a>
    </div>
    <script>
      $(function () {
        const current = window.location.pathname.split("/");
        $('#menu div a').each(function(){
          const $this = $(this);
          if (current.indexOf($this.attr("href")) !== -1) {
            $this.parent().addClass("now");
          }
        })
      });
    </script>
  </div>

  
<h3><a name="Biography"></a>Biography</h3>

<p>
 Lidong Bing is the director of the Language Technology Lab at DAMO Academy of Alibaba Group. 
He received a Ph.D. from The Chinese University of Hong Kong and was a postdoc research fellow at Carnegie Mellon University. 
His research interests include large language models, vision-language models, and various low-resource and multilingual NLP problems.
Currently, he is serving as an Action Editor for Transactions of the Association for Computational Linguistics (TACL) and ACL Rolling Review (ARR), 
as well as Area Chair for AI conferences and Associate Editor for AI journals. 
</br>
The NLP techniques developed by the lab served many business scenarios of Alibaba and its globalization strategy. 
Current projects that the lab is focusing on include SeaLLMs (<a href="https://huggingface.co/SeaLLMs/SeaLLM-7B-v2">[tech memo]</a> 
	    <a href="https://huggingface.co/spaces/SeaLLMs/SeaLLM-7B">[demo]</a> <a href="https://arxiv.org/abs/2312.00738">[paper]</a>),
	  a family of language models optimized for Southeast Asian (SEA) languages,
	  and Video-LLaMA ( <a href="https://github.com/DAMO-NLP-SG/Video-LLaMA">code</a>
		  <a href="https://huggingface.co/spaces/DAMO-NLP-SG/Video-LLaMA">[demo]</a>
	  <a href="https://arxiv.org/abs/2306.02858">[paper]</a>), an instruction-tuned audio-visual language model. 
</p> 

  <h3 id="News">News</h3>
    <ul>

    <li> 
    Feb 2024. We released Version 2 of SeaLLMs (<a href="https://huggingface.co/SeaLLMs/SeaLLM-7B-v2">tech memo</a>, 
	    <a href="https://huggingface.co/spaces/SeaLLMs/SeaLLM-7B">demo</a>). </li>
      
    <li> 
    Jan 2024. Three papers were accepted at <a href="https://iclr.cc/">ICLR 2024</a>. </li>
   
    <li> 
    Nov 2023. We released an LLM, named SeaLLMs (<a href="https://arxiv.org/abs/2312.00738">Paper</a> <a href="https://huggingface.co/SeaLLMs/SeaLLM-Chat-13b">DEMO</a>), which has quite good capabilities for the languages in Southeast Asia. </li>
    
        
    <li> 
    Nov 2023. We proposed <a href="https://arxiv.org/abs/2311.09277">Contrastive Chain-of-Thought Prompting</a>, which for the first time explores whether LLMs can also learn from the invalid chain of thought. </li>
        
    <li> 
    Oct 2023. Seven papers were accepted at <a href="https://2023.emnlp.org/">EMNLP 2023</a>. </li>
          
    <li> 
    Sep 2023. Two papers were accepted at <a href="https://nips.cc/">NeurIPS 2023</a>. </li>

    <li> 
    June 2023. Serve as an AC of <a href="https://2023.emnlp.org/">EMNLP 2023</a> for the theme track: Large Language Models and the Future of NLP. </li>

    <li> 
    May 2023. 17 papers were accepted at <a href="https://2023.aclweb.org/">ACL 2023</a>, 10 at the main conference, and 7 at the findings. </li>

    <!--<li> 
    Dec 2022. Invited to serve as an AC of <a href="https://2023.aclweb.org/">ACL 2023</a>. </li>
    
    <li> 
    Oct 2022. Eight papers were accepted at the main conference of <a href="https://2022.emnlp.org/">EMNLP 2022</a>. </li>
    
    <li> 
    Sep 2022. Three papers were accepted at <a href="https://coling2022.org/">COLING 2022</a> main conference. </li>
    
    <li> 
    April 2022. Invited to serve as an Action Editor for <a href="https://transacl.org/ojs/index.php/tacl/index">TACL</a>. </li>
        
    <li> 
    Feb 2022. Six papers were accepted at <a href="https://2022.aclweb.org/">ACL 2022</a>, 3 at the main conference and 3 at the findings. </li>
         
    <li> 
    Oct 2021. Invited to serve as an Action Editor for <a href="https://aclrollingreview.org/">ACL Rolling Review</a>. </li>
        
    <li> 
    Aug 2021. Four papers were accepted at <a href="https://2021.emnlp.org/">EMNLP 2021</a>, 2 at the main conference and 2 at the findings. </li>
        
          <li> 
    May 2021. Seven papers were accepted at <a href="https://2021.aclweb.org/">ACL 2021</a> main conference. </li>
        
    <li> 
    April 2021. Invited to serve as an AC of <a href="https://2021.emnlp.org/">EMNLP 2021</a> for the Sentiment Analysis, Stylistic Analysis, and Argument Mining track. </li>
       
       
    <li> 
    Jan 2021. Invited to serve as a Social Media Co-Chair of <a href="https://2021.aclweb.org/">ACL 2021</a>. </li>
        
        
    <li> 
    Nov 2020. Invited to serve as an AC of <a href="https://2021.aclweb.org/">ACL 2021</a> for the Sentiment Analysis, Stylistic Analysis, and Argument Mining track. </li>
        
        
    <li> 
    Sep 2020. Ten papers were accepted at <a href="https://2020.emnlp.org/">EMNLP 2020</a>, 9 at the main conference, 1 at the findings. </li>
        
        
    <li> 
    Sep 2020. One paper was accepted at <a href="https://coling2020.org/">COLING 2020</a> and one paper was accetped at <a href="http://aacl2020.org/">AACL 2020</a>. </li>
       
        
    <li> 
    Apr 2020. Two papers were accepted at <a href="https://acl2020.org/">ACL 2020</a> and one paper was accetped at <a href="https://www.ijcai20.org/">IJCAI 2020</a>. </li>
       
        
    <li> 
    Nov 2019. Four papers were accepted at <a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a>. </li>
       
        
    <li> 
    Aug 2019. Eight papers were accepted at <a href="https://www.emnlp-ijcnlp2019.org/">EMNLP 2019</a>. </li>
        
        
    <li> 
    May 2019. One paper was accetped at <a href="https://www.ijcai19.org/">IJCAI 2019</a>. </li>
                
    <li> 
    January 2019, I gave a talk on "Text Generation, Editing and Summarization" at the National University of Singapore, here is <a href="pub/TextGeneration_NUS_2019-Jan-18_v2.pdf">the slides</a>. 
    </li>
        
        
    <li> 
    January 2019. One paper was accetped at <a href="https://www2019.thewebconf.org/">WWW 2019</a>. 
    </li>-->

    </ul>
  

  <h3 id="Publications">Selected Publications (<a href="./research.html#Publications">Full List</a>, 
	  <a href="https://github.com/DAMO-NLP-SG">GitHub</a>, 
	  <a href="https://scholar.google.com/citations?user=_oYzrzAAAAAJ&hl=en"> Google Scholar</a>,
	  <a href="http://dblp.uni-trier.de/pers/hd/b/Bing:Lidong"> DBLP</a>) </h3>
	<ul>
        <li>
          <p> <font size="3.5"><b>SeaLLMs -- Large Language Models for Southeast Asia </b>
		  <a href="https://arxiv.org/abs/2312.00738">[paper]</a> 
		  <a href="https://huggingface.co/SeaLLMs/SeaLLM-Chat-13b">[demo]</a>
		  <a href="https://github.com/DAMO-NLP-SG/SeaLLMs">[code]</a>.
		  Xuan-Phi Nguyen, Wenxuan Zhang, Xin Li, Mahani Aljunied, Qingyu Tan, Liying Cheng, Guanzheng Chen, Yue Deng, Sen Yang, Chaoqun Liu, Hang Zhang, Lidong Bing. 
		  <i>Preprint arXiv:2312.00738</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Contrastive Chain-of-Thought Prompting </b>
		  <a href="https://arxiv.org/abs/2311.09277">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/contrastive-cot">[code]</a>.
		  Yew Ken Chia, Guizhen Chen, Luu Anh Tuan, Soujanya Poria, Lidong Bing. 
		  <i>Preprint arXiv:2311.09277</i>, 2023.<br/></font>
	   </p>
        </li>
	

	
        <li>
          <p> <font size="3.5"><b>Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding </b>
		  <a href="https://arxiv.org/abs/2311.16922">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/VCD">[code]</a>.
		  Sicong Leng, Hang Zhang, Guanzheng Chen, Xin Li, Shijian Lu, Chunyan Miao, Lidong Bing. 
		  <i>Preprint arXiv:2311.16922</i>, 2023.<br/></font>
	   </p>
        </li>
	

	
        <li>
          <p> <font size="3.5"><b>CLEX: Continuous Length Extrapolation for Large Language Models </b>
		  <a href="https://arxiv.org/abs/2310.16450">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/CLEX">[code]</a>.
		  Guanzheng Chen, Xin Li, Zaiqiao Meng, Shangsong Liang, Lidong Bing. 
		  <i>Preprint arXiv:2310.16450</i>, 2023.<br/></font>
	   </p>
        </li>


	
        <li>
          <p> <font size="3.5"><b>Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs </b>
		  <a href="https://arxiv.org/abs/2311.09802">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/CaRing">[code]</a>.
		  Sen Yang, Xin Li, Leyang Cui, Lidong Bing, Wai Lam. 
		  <i>Preprint arXiv:2311.09802</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>Towards Robust Temporal Reasoning of Large Language Models via a Multi-Hop QA Dataset and Pseudo-Instruction Tuning </b>
		  <a href="https://arxiv.org/abs/2311.09821">[paper]</a> 
		  <a href="https://lidongbing.github.io/">[code]</a>.
		  Qingyu Tan, Hwee Tou Ng, Lidong Bing. 
		  <i>Preprint arXiv:2311.09821</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>Semantic-Aware Contrastive Sentence Representation Learning with Large Language Models </b>
		  <a href="https://arxiv.org/abs/2310.10962">[paper]</a> 
		  <a href="https://lidongbing.github.io/">[code]</a>.
		  Huiming Wang, Liying Cheng, Zhaodonghui Li, De Wen Soh, Lidong Bing. 
		  <i>Preprint arXiv:2310.10962</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>Multilingual Jailbreak Challenges in Large Language Models </b>
		  <a href="https://arxiv.org/abs/2310.06474">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/multilingual-safety-for-LLMs">[code]</a>.
		  Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing. 
		  <i>Preprint arXiv:2310.06474</i>, 2023.<br/></font>
	   </p>
        </li>

	<li>
          <p> <font size="3.5"><b>Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding </b>
		  <a href="https://arxiv.org/abs/2306.02858">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/Video-LLaMA">[code]</a>
		  <a href="https://huggingface.co/spaces/DAMO-NLP-SG/Video-LLaMA">[demo (Hugging Face)]</a>
		  <a href="https://www.modelscope.cn/studios/damo/video-llama/summary">[demo (ModelScope)]</a>
		  <a href="https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-Series">[checkpoints]</a>.
		  Hang Zhang, Xin Li, Lidong Bing. 
		  <i>Demo Track of The Conference on Empirical Methods in Natural Language Processing (<b>EMNLP'23 Demo</b>)</i>, 2023.<br/></font>
	   </p>
        </li>

        <li>
          <p> <font size="3.5"><b>Once Upon a Time in Graph: Relative-Time Pretraining for Complex Temporal Reasoning </b>
		  <a href="https://lidongbing.github.io/">[paper]</a> <a href="https://lidongbing.github.io/">[code]</a>.
		  Sen Yang, Xin Li, Lidong Bing, Wai Lam.
		  <i>The Conference on Empirical Methods in Natural Language Processing (<b>EMNLP'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models </b>
		  <a href="https://arxiv.org/abs/2304.01933">[paper]</a> <a href="https://github.com/AGI-Edgerunners/LLM-Adapters">[code]</a>.
		  Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, Roy Ka-Wei Lee. 
		  <i>The Conference on Empirical Methods in Natural Language Processing (<b>EMNLP'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>

        <li>
          <p> <font size="3.5"><b>Is GPT-4 a Good Data Analyst? </b>
		  <a href="https://arxiv.org/abs/2305.15038">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/GPT4-as-DataAnalyst">[code]</a>.
		  Liying Cheng, Xingxuan Li, Lidong Bing. 
		  <i>Findings of The Conference on Empirical Methods in Natural Language Processing (<b>Findings of EMNLP'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>
		
        <li>
          <p> <font size="3.5"><b>Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization </b>
		  <a href="https://arxiv.org/abs/2305.13091">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/LLM_summeval">[code]</a>.
		  Chenhui Shen, Liying Cheng, Yang You, Xuan-Phi Nguyen, Lidong Bing. 
		  <i>Findings of The Conference on Empirical Methods in Natural Language Processing (<b>Findings of EMNLP'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>

	
        <li>
          <p> <font size="3.5"><b>
		  M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models </b>
		  <a href="https://arxiv.org/abs/2306.05179">[paper]</a> 
		  <a href="https://github.com/DAMO-NLP-SG/M3Exam">[code]</a>.
		  Wenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia, Lidong Bing. 
		  <i>Advances in Neural Information Processing Systems 36 (<b>NeurIPS'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>

	
        <li>
          <p> <font size="3.5"><b>
		  From Cloze to Comprehension: Retrofitting Pre-trained Masked Language Model to Pre-trained Machine Reader </b>
		  <a href="https://arxiv.org/abs/2212.04755">[paper]</a>
		  <a href="https://github.com/DAMO-NLP-SG/PMR">[code]</a>.
		  Weiwen Xu, Xin Li, Wenxuan Zhang, Meng Zhou, Wai Lam, Luo Si, Lidong Bing. 
		  <i>Advances in Neural Information Processing Systems 36 (<b>NeurIPS'23</b>)</i>, 2023.<br/></font>
	   </p>
        </li>

	
        <li>
          <p> <font size="3.5"><b>Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts </b>
		  <a href="https://arxiv.org/abs/2306.11372">[paper]</a> <a href="https://lidongbing.github.io/">[code]</a>.
		  Xuan-Phi Nguyen, Sharifah Mahani Aljunied, Shafiq Joty, Lidong Bing. 
		  <i>Preprint arXiv:2306.11372</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models </b>
		  <a href="https://arxiv.org/abs/2306.04757">[paper]</a> <a href="https://github.com/declare-lab/instruct-eval">[code]</a>.
		  Yew Ken Chia, Pengfei Hong, Lidong Bing, Soujanya Poria. 
		  <i>Preprint arXiv:2306.04757</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources </b>
		  <a href="https://arxiv.org/abs/2305.13269">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/chain-of-knowledge">[code]</a>.
		  Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Shafiq Joty, Soujanya Poria, Lidong Bing. 
		  <i>Preprint arXiv:2305.13269</i>, 2023.<br/></font>
	   </p>
        </li>
	
        <li>
          <p> <font size="3.5"><b>Sentiment Analysis in the Era of Large Language Models: A Reality Check </b>
		  <a href="https://arxiv.org/abs/2305.15005">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/LLM-Sentiment">[code]</a>.
		  Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing. 
		  <i>Preprint arXiv:2305.15005</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines </b>
		  <a href="https://arxiv.org/abs/2304.11076">[paper]</a> [blog article 
		  <a href="https://zhuanlan.zhihu.com/p/605915549"> (ZH)</a>, 
		  <a href="https://dev.to/ruochenzhao3/can-chatgpt-like-generative-models-guarantee-factual-accuracy-on-the-mistakes-of-microsofts-new-bing-111b">(EN)</a>].
		  Ruochen Zhao, Xingxuan Li, Yew Ken Chia, Bosheng Ding, Lidong Bing. <i>Preprint arXiv:2304.11076</i>, 2023.
		   <i>Follow-up reports by <a href="https://www.cnn.com/2023/02/14/tech/microsoft-bing-ai-errors/index.html">CNN</a>, 
			  <a href="https://www.cnbc.com/2023/02/14/microsoft-bing-ai-made-several-errors-in-launch-demo-last-week-.html">CNBC</a>, 
			  <a href="https://fortune.com/2023/02/15/microsoft-bing-ai-errors-demo-google-bard-chatgpt/">FORTUNE, </a></i>etc.<br/></font>
	   </p>
        </li>
	
	
	
        <li>
          <p> <font size="3.5"><b>mPMR: A Multilingual Pre-trained Machine Reader at Scale </b>
		  <a href="https://aclanthology.org/2023.acl-short.131.pdf">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/PMR">[code]</a>.
		  Weiwen Xu, Xin Li, Wai Lam, Lidong Bing. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Reasoning Implicit Sentiment with Chain-of-Thought Prompting </b>
		  <a href="https://aclanthology.org/2023.acl-short.101.pdf">[paper]</a> <a href="https://github.com/scofield7419/THOR-ISA">[code]</a>.
		  Hao Fei, Bobo Li, Qian Liu, Lidong Bing, Fei Li, Tat-Seng Chua. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework </b>
		  <a href="https://aclanthology.org/2023.acl-long.320.pdf">[paper]</a> <a href="https://github.com/RuochenZhao/Verify-and-Edit">[code]</a>. 
		  Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, Lidong Bing. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Is GPT-3 a Good Data Annotator? </b>
		  <a href="https://aclanthology.org/2023.acl-long.626.pdf">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/LLM-Data-Annotator">[code]</a>.
		  Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, Lidong Bing. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
	
        <li>
          <p> <font size="3.5"><b>Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning </b>
		  <a href="https://aclanthology.org/2023.acl-long.222.pdf">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/ContProto">[code]</a>.
		  Ran Zhou, Xin Li, Lidong Bing, Erik Cambria, Chunyan Miao. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
	
        <li>
          <p> <font size="3.5"><b>Bidirectional Generative Framework for Cross-domain Aspect-based Sentiment Analysis </b>
		  <a href="https://aclanthology.org/2023.acl-long.686.pdf">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/BGCA">[code]</a>.
		  Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
        <li>
          <p> <font size="3.5"><b>Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models </b>
		  <a href="https://aclanthology.org/2023.acl-long.828.pdf">[paper]</a> <a href="https://github.com/DAMO-NLP-SG/TempReason">[code]</a>.
		  Qingyu Tan, Hwee Tou Ng, Lidong Bing. 
		  <i>The 61th Annual Meeting of the Association for Computational Linguistics (ACL'23)</i>, 2023.<br/></font>
	   </p>
        </li>
	
	
	
  </ul>
	
	

  <h3><a name="Talks"></a>Talks</h3>
  <ul>
    <li> Nov 2023. Invited talk on "Research and Implementation of Large Language Models at Alibaba DAMO Academy" at <a href="https://wing-nus.github.io/ssnlp-2023/">SSNLP 2023</a>.</li>
    <li> Mar-Apr 2023. Invited talk on "Towards Solving Low-resource & Multilingual NLP Problems and a Pilot Study with LLMs" at Nanjing, Zhejiang, Fudan, and Shanghai Jiao Tong universities.</li>
  </ul>

  <h3><a name="Professional_Activities"></a>Professional Service</h3>
  <ul>
    <li>
      <p><b>Associate/Action Editor and Reviewer of journals</b>:<br/> 
        Transactions of the Association for Computational Linguistics (TACL)<br/> 
        ACM Transactions on Information Systems (TOIS)<br/> 
        Computational Linguistics (CL)<br/> 
        IEEE Transactions on Knowledge and Data Engineering (TKDE)<br/> 
        ACM Transactions on the Web (TWEB)<br/> 
        ACM Transactions on Intelligent Systems and Technology (ACM TIST)<br/> 
        Neurocomputing<br/>
        Neural Networks<br/>
        Neural Computing and Applications (NCA)<br/>
        Knowledge-based Systems (KBS) <br/>
        Information Processing and Management (IPM) <br/>
      </p>
    </li>
    <li>
      <p><b>Regular AC, SPC and PC of conferences</b>:<br/> 
        The Annual Meeting of the Association for Computational Linguistics (ACL)<br/> 
        The Conference on Empirical Methods in Natural Language Processing (EMNLP)<br/> 
        The AAAI Conference on Artificial Intelligence (AAAI)<br/> 
        The International Joint Conference on Artificial Intelligence (IJCAI) <br/> 
        The Conference on Neural Information Processing Systems (NeurIPS)  <br/> 
        The International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)<br/>  
        The International World Wide Web Conference (WWW) <br/>
        The ACM International Conference on Information and Knowledge Management (CIKM) <br/> 
      </p>
    </li>
  </ul>
</div>
</body>

</html>
